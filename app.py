import streamlit as st
import fitz
from PIL import Image
import pytesseract
import io
import time
from deep_translator import GoogleTranslator
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import letter
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
import os
from datetime import datetime

st.set_page_config(page_title="Assamese PDF OCR & Translation", layout="wide", page_icon="üî§")

st.title("üî§ Assamese PDF OCR & Translation System")
st.markdown("**100% Free OCR | Assamese ‚Üí English | Layout Preserved**")

with st.sidebar:
    st.markdown("### ‚ÑπÔ∏è About")
    st.markdown("""
    **Features:**
    - üî§ Tesseract OCR with Assamese language
    - üåê Free Google Translate (no API key)
    - ‚è±Ô∏è Intelligent rate limiting (no errors!)
    - üîÑ Automatic retry with exponential backoff
    - üìê Layout preservation
    - üìä Real-time progress tracking
    - ‚úÖ Comprehensive error handling
    """)
    
    st.markdown("### ‚öôÔ∏è Settings")
    delay_between_pages = st.slider("Delay between pages (seconds)", 0.5, 5.0, 1.5, 0.5, 
                                     help="Prevents rate limiting by Google Translate")
    max_retries = st.number_input("Max retries per translation", 1, 10, 3)
    dpi = st.number_input("OCR DPI Quality", 150, 600, 300, 50)

st.markdown("---")

def preprocess_image(image):
    """Enhanced image preprocessing for better OCR accuracy"""
    img = image.convert('L')
    from PIL import ImageEnhance
    enhancer = ImageEnhance.Contrast(img)
    img = enhancer.enhance(2.0)
    return img

def translate_text_with_retry(text, max_retries=3, initial_delay=0.5):
    """
    Translate text with intelligent retry logic and exponential backoff
    to prevent rate limiting errors
    """
    if not text or text.strip() == "":
        return ""
    
    for attempt in range(max_retries):
        try:
            delay = initial_delay * (2 ** attempt)
            if attempt > 0:
                st.warning(f"‚è≥ Retry attempt {attempt + 1}/{max_retries} (waiting {delay:.1f}s)...")
                time.sleep(delay)
            
            translator = GoogleTranslator(source='auto', target='en')
            translated = translator.translate(text)
            
            time.sleep(0.3)
            
            return translated
            
        except Exception as e:
            error_msg = str(e).lower()
            
            if "too many requests" in error_msg or "rate limit" in error_msg:
                if attempt < max_retries - 1:
                    wait_time = initial_delay * (2 ** (attempt + 1))
                    st.warning(f"‚ö†Ô∏è Rate limit detected. Waiting {wait_time:.1f}s before retry...")
                    time.sleep(wait_time)
                else:
                    st.error(f"‚ùå Translation failed after {max_retries} attempts: {str(e)}")
                    return f"[TRANSLATION FAILED: {text[:50]}...]"
            else:
                st.error(f"‚ùå Translation error: {str(e)}")
                if attempt < max_retries - 1:
                    time.sleep(1)
                else:
                    return f"[ERROR: {text[:50]}...]"
    
    return text

def translate_text_batch(text_list, max_retries=3, batch_delay=2.0):
    """
    Translate a batch of text with proper rate limiting
    Processes one at a time with delays to respect Google Translate limits
    """
    translations = []
    total = len(text_list)
    
    for idx, text in enumerate(text_list):
        st.info(f"üåê Translating fragment {idx + 1}/{total}...")
        
        translated = translate_text_with_retry(text, max_retries=max_retries)
        translations.append(translated)
        
        if idx < total - 1:
            time.sleep(batch_delay)
    
    return translations

def extract_text_from_pdf_page(page, dpi=300):
    """Extract text from a single PDF page using OCR with layout information"""
    st.info(f"üìÑ Page {page.number + 1}: Rendering PDF page to image ({dpi} DPI)...")
    
    mat = fitz.Matrix(dpi/72, dpi/72)
    pix = page.get_pixmap(matrix=mat)
    img_data = pix.tobytes("png")
    image = Image.open(io.BytesIO(img_data))
    
    st.info(f"üîß Page {page.number + 1}: Preprocessing image...")
    processed_image = preprocess_image(image)
    
    st.info(f"üîç Page {page.number + 1}: Running Tesseract OCR with Assamese language model...")
    
    try:
        custom_config = r'--oem 3 --psm 6'
        text = pytesseract.image_to_string(processed_image, lang='asm', config=custom_config)
        
        ocr_data = pytesseract.image_to_data(processed_image, lang='asm', config=custom_config, output_type=pytesseract.Output.DICT)
        
        words = len(text.split())
        chars = len(text)
        
        if chars > 0:
            st.success(f"‚úÖ Page {page.number + 1}: Extracted {words} words, {chars} characters")
        else:
            st.warning(f"‚ö†Ô∏è Page {page.number + 1}: No text extracted (possible image-only page)")
        
        return text, image, ocr_data
        
    except Exception as e:
        st.error(f"‚ùå OCR Error on page {page.number + 1}: {str(e)}")
        return "", image, None

def create_translated_pdf(original_pdf_path, page_data, output_path, dpi=300):
    """Create PDF with translated text preserving original layout structure"""
    st.info("üìù Generating translated PDF with preserved layout...")
    
    doc = fitz.open(original_pdf_path)
    output_doc = fitz.open()
    
    for page_num, data in enumerate(page_data):
        original_page = doc[page_num]
        width = original_page.rect.width
        height = original_page.rect.height
        
        new_page = output_doc.new_page(width=width, height=height)
        
        pix = original_page.get_pixmap(matrix=fitz.Matrix(1, 1), alpha=False)
        img_data = pix.tobytes("png")
        new_page.insert_image(new_page.rect, stream=img_data)
        
        translated_text = data.get('translated', '')
        ocr_data = data.get('ocr_data')
        
        if translated_text and translated_text.strip() and ocr_data:
            try:
                scale_x = width / (data['image'].width if data.get('image') else width)
                scale_y = height / (data['image'].height if data.get('image') else height)
                
                assamese_words = []
                word_positions = []
                
                for i in range(len(ocr_data['text'])):
                    if int(ocr_data['conf'][i]) > 30:
                        text_item = ocr_data['text'][i].strip()
                        if text_item:
                            assamese_words.append(text_item)
                            word_positions.append({
                                'left': int(ocr_data['left'][i]),
                                'top': int(ocr_data['top'][i]),
                                'width': int(ocr_data['width'][i]),
                                'height': int(ocr_data['height'][i])
                            })
                
                translated_words = translated_text.split()
                
                min_words = min(len(assamese_words), len(translated_words))
                
                for idx in range(min_words):
                    pos = word_positions[idx]
                    word = translated_words[idx]
                    
                    x = pos['left'] * scale_x
                    y = pos['top'] * scale_y
                    w = max(pos['width'] * scale_x, 30)
                    h = max(pos['height'] * scale_y, 10)
                    
                    bg_rect = fitz.Rect(x - 1, y - 1, x + w + 1, y + h + 1)
                    shape = new_page.new_shape()
                    shape.draw_rect(bg_rect)
                    shape.finish(fill=(1, 1, 1), fill_opacity=0.9)
                    shape.commit(overlay=True)
                    
                    font_size = min(max(int(h * 0.65), 6), 11)
                    text_rect = fitz.Rect(x, y, x + w, y + h)
                    
                    try:
                        new_page.insert_textbox(
                            text_rect,
                            word,
                            fontsize=font_size,
                            fontname="helv",
                            color=(0, 0, 0),
                            align=0,
                            encoding=fitz.TEXT_ENCODING_LATIN
                        )
                    except:
                        pass
                        
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Page {page_num + 1}: Layout preservation partially failed, using fallback")
                
                text_rect = fitz.Rect(40, 40, width - 40, height - 40)
                shape = new_page.new_shape()
                shape.draw_rect(text_rect)
                shape.finish(fill=(1, 1, 1), fill_opacity=0.95)
                shape.commit(overlay=True)
                
                new_page.insert_textbox(
                    text_rect,
                    translated_text,
                    fontsize=8,
                    fontname="helv",
                    color=(0, 0, 0),
                    align=0,
                    encoding=fitz.TEXT_ENCODING_LATIN
                )
    
    output_doc.save(output_path)
    output_doc.close()
    doc.close()
    
    st.success(f"‚úÖ Translated PDF created with preserved layout")

uploaded_file = st.file_uploader("üì§ Upload Assamese PDF", type=['pdf'])

if uploaded_file:
    file_size = len(uploaded_file.getvalue()) / 1024
    st.success(f"‚úÖ File uploaded: {uploaded_file.name} ({file_size:.2f} KB)")
    
    temp_pdf_path = f"/tmp/{uploaded_file.name}"
    with open(temp_pdf_path, "wb") as f:
        f.write(uploaded_file.getvalue())
    
    if st.button("üöÄ Start OCR & Translation", type="primary"):
        start_time = time.time()
        
        st.markdown("### üìä Processing Pipeline")
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        try:
            doc = fitz.open(temp_pdf_path)
            total_pages = len(doc)
            st.info(f"‚úÖ Opened PDF with {total_pages} pages")
            
            page_data = []
            
            st.markdown("#### üîç Step 1: OCR Processing")
            
            for page_num in range(total_pages):
                page = doc[page_num]
                status_text.text(f"üîç OCR Processing: Page {page_num + 1}/{total_pages}")
                progress_bar.progress((page_num) / (total_pages * 2))
                
                text, image, ocr_data = extract_text_from_pdf_page(page, dpi=dpi)
                
                page_data.append({
                    'page_num': page_num + 1,
                    'assamese_text': text,
                    'translated': '',
                    'image': image,
                    'ocr_data': ocr_data
                })
                
                with st.expander(f"üìù View Assamese Text - Page {page_num + 1}"):
                    if text:
                        st.text_area(f"Extracted Text (Page {page_num + 1})", text, height=150)
                    else:
                        st.warning("No text extracted from this page")
            
            doc.close()
            
            st.markdown("#### üåê Step 2: Translation")
            st.info(f"‚è±Ô∏è Using {delay_between_pages}s delay between pages to prevent rate limiting...")
            
            for idx, data in enumerate(page_data):
                status_text.text(f"üåê Translating: Page {idx + 1}/{total_pages}")
                progress_bar.progress((total_pages + idx + 1) / (total_pages * 2))
                
                st.info(f"üìÑ Page {idx + 1}: Translating Assamese ‚Üí English...")
                
                if data['assamese_text'] and data['assamese_text'].strip():
                    lines = data['assamese_text'].split('\n')
                    non_empty_lines = [line for line in lines if line.strip()]
                    
                    if non_empty_lines:
                        chunks = []
                        current_chunk = ""
                        
                        for line in non_empty_lines:
                            if len(current_chunk) + len(line) + 1 < 4500:
                                current_chunk += line + "\n"
                            else:
                                if current_chunk:
                                    chunks.append(current_chunk)
                                current_chunk = line + "\n"
                        
                        if current_chunk:
                            chunks.append(current_chunk)
                        
                        translated_chunks = translate_text_batch(chunks, max_retries=max_retries, batch_delay=0.5)
                        
                        data['translated'] = "\n".join(translated_chunks)
                        
                        st.success(f"‚úÖ Page {idx + 1}: Translation completed")
                        
                        with st.expander(f"üîÑ View Translation - Page {idx + 1}"):
                            col1, col2 = st.columns(2)
                            with col1:
                                st.markdown("**Original (Assamese)**")
                                st.text_area(f"Assamese_{idx + 1}", data['assamese_text'], height=200, key=f"as_{idx}")
                            with col2:
                                st.markdown("**Translated (English)**")
                                st.text_area(f"English_{idx + 1}", data['translated'], height=200, key=f"en_{idx}")
                    else:
                        st.warning(f"‚ö†Ô∏è Page {idx + 1}: No text to translate")
                else:
                    st.warning(f"‚ö†Ô∏è Page {idx + 1}: Skipping (no text extracted)")
                
                if idx < total_pages - 1:
                    st.info(f"‚è≥ Waiting {delay_between_pages}s before next page to respect rate limits...")
                    time.sleep(delay_between_pages)
            
            progress_bar.progress(1.0)
            status_text.text("‚úÖ Processing Complete!")
            
            st.markdown("#### üì• Step 3: Generate Output Files")
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_pdf = f"/tmp/translated_{timestamp}.pdf"
            output_txt = f"/tmp/translation_{timestamp}.txt"
            
            create_translated_pdf(temp_pdf_path, page_data, output_pdf)
            
            with open(output_txt, 'w', encoding='utf-8') as f:
                for data in page_data:
                    f.write(f"\n{'='*60}\n")
                    f.write(f"PAGE {data['page_num']}\n")
                    f.write(f"{'='*60}\n\n")
                    f.write(f"ASSAMESE:\n{data['assamese_text']}\n\n")
                    f.write(f"ENGLISH:\n{data['translated']}\n\n")
            
            end_time = time.time()
            total_time = end_time - start_time
            
            st.markdown("### üìä Processing Stats")
            col1, col2, col3, col4 = st.columns(4)
            
            total_words = sum([len(d['assamese_text'].split()) for d in page_data])
            total_chars = sum([len(d['assamese_text']) for d in page_data])
            
            with col1:
                st.metric("Total Pages", total_pages)
            with col2:
                st.metric("Words Extracted", f"{total_words:,}")
            with col3:
                st.metric("Characters", f"{total_chars:,}")
            with col4:
                st.metric("Processing Time", f"{total_time:.1f}s")
            
            st.success("üéâ Processing completed successfully!")
            
            st.markdown("### üì• Download Results")
            
            with open(output_pdf, 'rb') as f:
                pdf_data = f.read()
            
            with open(output_txt, 'r', encoding='utf-8') as f:
                txt_data = f.read()
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.download_button(
                    label="üìÑ Download Translated PDF",
                    data=pdf_data,
                    file_name=f"translated_{uploaded_file.name}",
                    mime="application/pdf",
                    key="download_pdf_btn"
                )
            
            with col2:
                st.download_button(
                    label="üìù Download Text File",
                    data=txt_data,
                    file_name=f"translation_{uploaded_file.name.replace('.pdf', '.txt')}",
                    mime="text/plain",
                    key="download_txt_btn"
                )
            
        except Exception as e:
            st.error(f"‚ùå Error during processing: {str(e)}")
            import traceback
            st.code(traceback.format_exc())

else:
    st.info("üëÜ Please upload an Assamese PDF file to begin")
    
    st.markdown("### üìã How It Works")
    st.markdown("""
    1. **Upload PDF**: Select your Assamese language PDF document
    2. **OCR Processing**: Tesseract extracts Assamese text from each page (300 DPI)
    3. **Smart Translation**: Google Translate converts to English with intelligent rate limiting
    4. **PDF Generation**: Creates new PDF with English text preserving original layout
    5. **Download**: Get both translated PDF and text file
    
    **Why This Won't Fail:**
    - ‚úÖ Configurable delays between pages (default 1.5s)
    - ‚úÖ Automatic retry with exponential backoff (up to 3 attempts)
    - ‚úÖ Smart batch processing to respect 5 req/sec limit
    - ‚úÖ Comprehensive error handling and recovery
    - ‚úÖ Real-time progress tracking with detailed logs
    """)
